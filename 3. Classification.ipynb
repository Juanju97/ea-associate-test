{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classification\n",
    "\n",
    "#### Juan Julián Cea Morán\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we have to import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "preproc_df = pickle.load(open(\"data/preproc_df.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Prepare datasets\n",
    "We have to create train and test dataset, so we have to split our dataset. But before do that, there are some operations that we need to perform.\n",
    "\n",
    "First of all, we have to encode the categories into diferent numeric labels, conforming the targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "preproc_df['Target'] = le.fit_transform([cat for cat in preproc_df['Category']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preprocessed</th>\n",
       "      <th>Category</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[read, book, town, everyone, uses, order, phar...</td>\n",
       "      <td>APR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[recipes, appreciated, family, small, large, r...</td>\n",
       "      <td>APR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[say, ease, author, even, made, effort, meet, ...</td>\n",
       "      <td>APR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[milady, found, good, vein, anita, blake, base...</td>\n",
       "      <td>APR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[somewhere, greece, gentlemen, decided, visit,...</td>\n",
       "      <td>APR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Preprocessed Category  Target\n",
       "0  [read, book, town, everyone, uses, order, phar...      APR       0\n",
       "1  [recipes, appreciated, family, small, large, r...      APR       0\n",
       "2  [say, ease, author, even, made, effort, meet, ...      APR       0\n",
       "3  [milady, found, good, vein, anita, blake, base...      APR       0\n",
       "4  [somewhere, greece, gentlemen, decided, visit,...      APR       0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need also to shuffle all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_df = preproc_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preprocessed</th>\n",
       "      <th>Category</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[first, one, related, database, conceptor, ide...</td>\n",
       "      <td>Conference_papers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[group, strikes, hearts, teenagers, reason, sp...</td>\n",
       "      <td>APR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[llama, presilla, especie, cordon, pequeno, se...</td>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[sucre, placed, force, across, mountains, chim...</td>\n",
       "      <td>PAN11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[rabotnicki, rabotnichki, kometal, equipo, fut...</td>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Preprocessed           Category  \\\n",
       "0  [first, one, related, database, conceptor, ide...  Conference_papers   \n",
       "1  [group, strikes, hearts, teenagers, reason, sp...                APR   \n",
       "2  [llama, presilla, especie, cordon, pequeno, se...          Wikipedia   \n",
       "3  [sucre, placed, force, across, mountains, chim...              PAN11   \n",
       "4  [rabotnicki, rabotnichki, kometal, equipo, fut...          Wikipedia   \n",
       "\n",
       "   Target  \n",
       "0       1  \n",
       "1       0  \n",
       "2       3  \n",
       "3       2  \n",
       "4       3  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time to split the dataset. To do that, we are gonna take 90% for train and 10% for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(preproc_df, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 3 3 3 3 3 2 1 3 3 0 3 3]\n",
      "[3 3 2 3 3 3 3 3 3 2 0 3 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "Y_train = np.asarray(train_df['Target'].tolist())\n",
    "print(Y_train[0:15])\n",
    "\n",
    "Y_test = np.asarray(test_df['Target'].tolist())\n",
    "print(Y_test[0:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Vectorize texts\n",
    "The next step is to vectorize text. Our ML models are not able to work with strings, so we need to convert those strings into numbers. To do that, there are different approaches.\n",
    "\n",
    "For the pourpose of this test, we are going to use some scikit-learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "Wall time: 18.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "tfidf_vect = TfidfVectorizer(use_idf=True)\n",
    "X_train = tfidf_vect.fit_transform([' '.join(text) for text in train_df['Preprocessed']])\n",
    "X_test = tfidf_vect.transform([' '.join(text) for text in test_df['Preprocessed']])\n",
    "\n",
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Implementing the model\n",
    "Once we have our data ready, it's time to test some models and get results. We are going to test models using scikit-learn library, which I said before is widely used in this domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Multinomial Naive Bayes**\n",
    "This classifier is suitable for text classification, since it is intended to be used with discrete features like word counts.\n",
    "\n",
    "First, we have to train the model using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 274 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is trained, it is ready to perform some predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8396022481625595"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
