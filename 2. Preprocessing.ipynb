{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Text Preprocessing\n",
    "#### Juan Julián Cea Morán\n",
    "---\n",
    "As we saw in the EDA section, we are working with text in 3 possible languages: english, spanish and french. We have no indication that the final system can work with more languages, so we will only focus on those three.\n",
    "\n",
    "This means that we are working with a mulitlingual dataset. To solve this task it will be necessary to apply textual pre-processing adapted to each of the different languages present in the dataset. \n",
    "\n",
    "There are several ways to achieve this requierement: for example, it could be done by building regular expressions so all exceptions founded in texts could be captured. Another option would be breaking the data apart by language and use specifict tools for each language.\n",
    "\n",
    "In this case we are using the second approach, so we have to identify th language of each text and then apply specifict transformation functions.\n",
    "\n",
    "The first step is to take pandas dataframe from EDA section and use the 'text' column to preprocess each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "docs_df = pickle.load(open(\"data/docs_df.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Text</th>\n",
       "      <th>Lang</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apr-book-0-en.txt</td>\n",
       "      <td>i read this book because in my town, everyone ...</td>\n",
       "      <td>en</td>\n",
       "      <td>APR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apr-book-1-en.txt</td>\n",
       "      <td>recipes appreciated by the family (small and l...</td>\n",
       "      <td>en</td>\n",
       "      <td>APR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apr-book-10-en.txt</td>\n",
       "      <td>i say no to ease ..... and not to the author w...</td>\n",
       "      <td>en</td>\n",
       "      <td>APR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apr-book-100-en.txt</td>\n",
       "      <td>milady has found a good vein: anita blake. bas...</td>\n",
       "      <td>en</td>\n",
       "      <td>APR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apr-book-1000-en.txt</td>\n",
       "      <td>460 bc, somewhere in greece: \"gentlemen, i dec...</td>\n",
       "      <td>en</td>\n",
       "      <td>APR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name                                               Text  \\\n",
       "0     apr-book-0-en.txt  i read this book because in my town, everyone ...   \n",
       "1     apr-book-1-en.txt  recipes appreciated by the family (small and l...   \n",
       "2    apr-book-10-en.txt  i say no to ease ..... and not to the author w...   \n",
       "3   apr-book-100-en.txt  milady has found a good vein: anita blake. bas...   \n",
       "4  apr-book-1000-en.txt  460 bc, somewhere in greece: \"gentlemen, i dec...   \n",
       "\n",
       "  Lang Category  \n",
       "0   en      APR  \n",
       "1   en      APR  \n",
       "2   en      APR  \n",
       "3   en      APR  \n",
       "4   en      APR  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to work with 'Text' column. Then, dump the result as a new column in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i read this book because in my town, everyone ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recipes appreciated by the family (small and l...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i say no to ease ..... and not to the author w...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>milady has found a good vein: anita blake. bas...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>460 bc, somewhere in greece: \"gentlemen, i dec...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Lang\n",
       "0  i read this book because in my town, everyone ...   en\n",
       "1  recipes appreciated by the family (small and l...   en\n",
       "2  i say no to ease ..... and not to the author w...   en\n",
       "3  milady has found a good vein: anita blake. bas...   en\n",
       "4  460 bc, somewhere in greece: \"gentlemen, i dec...   en"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_df = docs_df[['Text', 'Lang']]\n",
    "lang_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language identification\n",
    "There are some python libraries that address this issue. For example: \n",
    "* LangID: Developped by Lui Marco, is a standalone Language Identification (LangID) tool bassed on previous researchs by the authors. https://github.com/saffsd/langid.py\n",
    "* langdetect: Port of Nakatani Shuyo's language-detection library (version from 03/03/2014) to Python. https://github.com/Mimino666/langdetect\n",
    "* TextBlob: A popular Text Processing package for Python. It includes a module for language detection based on a Google API. Requires Internet conection. https://textblob.readthedocs.io/en/dev/\n",
    "\n",
    "Let's compare them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take text in the 3 languages\n",
    "en = lang_df.loc[(lang_df['Lang'] == 'en')][0:100]\n",
    "es = lang_df.loc[(lang_df['Lang'] == 'es')][0:100]\n",
    "fr = lang_df.loc[(lang_df['Lang'] == 'fr')][0:100]\n",
    "\n",
    "sample_texts = pd.concat([en, es, fr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langid\n",
    "\n",
    "_langid = [l [0] for l in sample_texts['Text'].apply(langid.classify)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "_langdetect = [l for l in sample_texts['Text'].apply(langdetect.detect)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "_textblob = [TextBlob(l).detect_language() for l in sample_texts['Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangID Error: 0\n",
      "LangDetect Error: 1\n",
      "TextBlob Error: 0\n"
     ]
    }
   ],
   "source": [
    "langid_error =  0\n",
    "langdetect_error = 0\n",
    "textblob_error = 0\n",
    "\n",
    "sample_texts_lang = [s for s in sample_texts['Lang']]\n",
    "\n",
    "for i in range(0, len(sample_texts_lang)):\n",
    "    if _langid[i] != sample_texts_lang[i]:\n",
    "        langid_error += 1\n",
    "    if _langdetect[i] != sample_texts_lang[i]:\n",
    "        langdetect_error += 1\n",
    "    if _textblob[i] != sample_texts_lang[i]:\n",
    "        textblob_error += 1\n",
    "        \n",
    "print('LangID Error:', langid_error)\n",
    "print('LangDetect Error:', langdetect_error)\n",
    "print('TextBlob Error:', textblob_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A we can see, we get similar results using any of this packages. We are going to use the first one, langID. Let's try it with the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_langid = [l [0] for l in lang_df['Text'].apply(langid.classify)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1656\n"
     ]
    }
   ],
   "source": [
    "error = 0\n",
    "\n",
    "full_langs = [s for s in lang_df['Lang']]\n",
    "\n",
    "for i in range(0, len(full_langs)):\n",
    "    if full_langid[i] != full_langs[i]:\n",
    "        error += 1\n",
    "\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, this approach can perform well with a little subsample of the original dataset, but it return 1656 miss classifications when using the entire dataset. Due to that, we are going to use a preprocessing function capable of perform well in every language.\n",
    "\n",
    "---\n",
    "### Cleaning and tokenize\n",
    "We have to build a function that takes every text sample and prepares it for being analyzed by our ML algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import unidecode\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "stopwords = stopwords.words(\"french\") + stopwords.words(\"english\") + stopwords.words(\"spanish\")\n",
    "\n",
    "def preprocess(text):\n",
    "    text = unidecode.unidecode(text.strip().lower())\n",
    "    \n",
    "    url_regex = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    text = url_regex.sub(' ', text)\n",
    "    \n",
    "    html_pattern = re.compile(r'<.?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "    text =  html_pattern.sub(' ', text)\n",
    "    \n",
    "    chars_regex = re.compile(r'[^\\w\\s]')\n",
    "    tweet = chars_regex.sub(' ', text)\n",
    "    \n",
    "    number_regex = re.compile(r'[\\d]+')\n",
    "    text = number_regex.sub(' ', text)\n",
    "    \n",
    "    text = ' '.join(text.split('\\''))\n",
    "    \n",
    "    text = word_tokenize(text)\n",
    "    \n",
    "    text = [word for word in text if]\n",
    "    \n",
    "    text = [word for word in text if word not in stopwords and len(word)>2]\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aafm', '___', 'ababa']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(\"I'aafm ___42ababa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "\n",
    "preprocessed = list()\n",
    "for text in docs_df['Text']:\n",
    "    preprocessed.append(preprocess(text))\n",
    "    \n",
    "docs_df = docs_df.drop(columns=['Preprocessed'])\n",
    "docs_df.insert(2, 'Preprocessed', preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Text</th>\n",
       "      <th>Preprocessed</th>\n",
       "      <th>Lang</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apr-book-0-en.txt</td>\n",
       "      <td>i read this book because in my town, everyone ...</td>\n",
       "      <td>[read, book, town, everyone, uses, order, phar...</td>\n",
       "      <td>en</td>\n",
       "      <td>APR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apr-book-1-en.txt</td>\n",
       "      <td>recipes appreciated by the family (small and l...</td>\n",
       "      <td>[recipes, appreciated, family, small, large, r...</td>\n",
       "      <td>en</td>\n",
       "      <td>APR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apr-book-10-en.txt</td>\n",
       "      <td>i say no to ease ..... and not to the author w...</td>\n",
       "      <td>[say, ease, ....., author, even, made, effort,...</td>\n",
       "      <td>en</td>\n",
       "      <td>APR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apr-book-100-en.txt</td>\n",
       "      <td>milady has found a good vein: anita blake. bas...</td>\n",
       "      <td>[milady, found, good, vein, anita, blake, base...</td>\n",
       "      <td>en</td>\n",
       "      <td>APR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apr-book-1000-en.txt</td>\n",
       "      <td>460 bc, somewhere in greece: \"gentlemen, i dec...</td>\n",
       "      <td>[somewhere, greece, gentlemen, decided, visit,...</td>\n",
       "      <td>en</td>\n",
       "      <td>APR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name                                               Text  \\\n",
       "0     apr-book-0-en.txt  i read this book because in my town, everyone ...   \n",
       "1     apr-book-1-en.txt  recipes appreciated by the family (small and l...   \n",
       "2    apr-book-10-en.txt  i say no to ease ..... and not to the author w...   \n",
       "3   apr-book-100-en.txt  milady has found a good vein: anita blake. bas...   \n",
       "4  apr-book-1000-en.txt  460 bc, somewhere in greece: \"gentlemen, i dec...   \n",
       "\n",
       "                                        Preprocessed Lang Category  \n",
       "0  [read, book, town, everyone, uses, order, phar...   en      APR  \n",
       "1  [recipes, appreciated, family, small, large, r...   en      APR  \n",
       "2  [say, ease, ....., author, even, made, effort,...   en      APR  \n",
       "3  [milady, found, good, vein, anita, blake, base...   en      APR  \n",
       "4  [somewhere, greece, gentlemen, decided, visit,...   en      APR  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Explore results\n",
    "Now that we have our texts preprocessed, it's time to explore the data and check if there are irrelevant terms not considered as stop words. This process is important because we want our model to perform well by only \"paying attention\" to relevant terms in the corpus.\n",
    "\n",
    "Let's generate TF-IDF of the results extract some insights. For this test, lets separate texts by language. For the moment we don't need to worry about categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_texts = [' '.join(text) for text in docs_df.loc[(docs_df['Lang'] == 'en')]['Preprocessed']]\n",
    "es_texts = [' '.join(text) for text in docs_df.loc[(docs_df['Lang'] == 'es')]['Preprocessed']]\n",
    "fr_texts = [' '.join(text) for text in docs_df.loc[(docs_df['Lang'] == 'fr')]['Preprocessed']]\n",
    "\n",
    "# total = [' '.join(text) for text in docs_df.loc[(docs_df['Lang'] == 'es')]['Preprocessed'][0:10000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "# English\n",
    "en_tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
    "en_tfidf = en_tfidf_vectorizer.fit_transform(en_texts)\n",
    "en_tfidf_feature_names = en_tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# Spanish\n",
    "es_tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
    "es_tfidf = es_tfidf_vectorizer.fit_transform(es_texts)\n",
    "es_tfidf_feature_names = es_tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# French\n",
    "fr_tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
    "fr_tfidf = fr_tfidf_vectorizer.fit_transform(fr_texts)\n",
    "fr_tfidf_feature_names = fr_tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# fr_tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
    "# fr_tfidf = fr_tfidf_vectorizer.fit_transform(total)\n",
    "# fr_tfidf_feature_names = fr_tfidf_vectorizer.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__',\n",
       " '____',\n",
       " '__________',\n",
       " '_____________',\n",
       " '____data',\n",
       " '____it',\n",
       " '____surrounded',\n",
       " '__forcetoc__location',\n",
       " '__init__',\n",
       " '__main__',\n",
       " '__name__',\n",
       " '__notoc__',\n",
       " '__notoc__ar',\n",
       " '__notoc__les',\n",
       " '__toc__',\n",
       " '__toc__descriptionginkgos',\n",
       " '__toc__etymologythe',\n",
       " '__toc__etymologywas',\n",
       " '__toc__historywith',\n",
       " '__toc__overviewayurveda',\n",
       " '__toc__taxonomythe',\n",
       " '__traverse__',\n",
       " '__venezia',\n",
       " '_adidas_snake_white',\n",
       " '_adidasonwhite',\n",
       " '_adidasstripesonwhite',\n",
       " '_adidasstripeswhite',\n",
       " '_adidaswhite',\n",
       " '_agency',\n",
       " '_alpha',\n",
       " '_analekta',\n",
       " '_article',\n",
       " '_asnl',\n",
       " '_asnl_ext',\n",
       " '_black_background',\n",
       " '_black_stripes',\n",
       " '_blackborder',\n",
       " '_blackbrown',\n",
       " '_blackshoulders',\n",
       " '_blackshoulders_blacksides',\n",
       " '_blackstripes',\n",
       " '_blueline',\n",
       " '_blueshoulders',\n",
       " '_bluestripes',\n",
       " '_blueupper',\n",
       " '_borderonblack',\n",
       " '_borderonwhite',\n",
       " '_bush_john_paul_ii_funeral',\n",
       " '_caption',\n",
       " '_chi',\n",
       " '_collarblue',\n",
       " '_collaronwhite',\n",
       " '_collarred',\n",
       " '_color',\n",
       " '_country',\n",
       " '_dp',\n",
       " '_dt',\n",
       " '_dv',\n",
       " '_dzheims',\n",
       " '_e',\n",
       " '_edn',\n",
       " '_entrance',\n",
       " '_euclid',\n",
       " '_facade',\n",
       " '_feyenoord',\n",
       " '_ffw_brehna_sachsen',\n",
       " '_fg',\n",
       " '_final',\n",
       " '_firstissue',\n",
       " '_flag',\n",
       " '_for',\n",
       " '_gastello_',\n",
       " '_genealogists',\n",
       " '_glossary',\n",
       " '_goldborder',\n",
       " '_gorges_dam_at_night',\n",
       " '_greenborder',\n",
       " '_greenlower',\n",
       " '_greenstripes',\n",
       " '_indiana',\n",
       " '_info',\n",
       " '_italya',\n",
       " '_italyh',\n",
       " '_just',\n",
       " '_k',\n",
       " '_km',\n",
       " '_kor',\n",
       " '_label',\n",
       " '_lahore_',\n",
       " '_lg',\n",
       " '_lightbluestripes',\n",
       " '_location',\n",
       " '_lprflowreport_',\n",
       " '_lrg',\n",
       " '_mullingar',\n",
       " '_myasnitskaya_',\n",
       " '_name',\n",
       " '_navyhorizontal',\n",
       " '_navyshoulders',\n",
       " '_navystripes',\n",
       " '_numeric',\n",
       " '_obverse',\n",
       " '_opn',\n",
       " '_orangehorizontal',\n",
       " '_palermo',\n",
       " '_parmenides',\n",
       " '_pierce_dash_midmount_platform',\n",
       " '_pierre',\n",
       " '_place',\n",
       " '_planetarium',\n",
       " '_position',\n",
       " '_pumper',\n",
       " '_ranaghan',\n",
       " '_red',\n",
       " '_red_stripes',\n",
       " '_red_stripes_red_sh_new',\n",
       " '_redborder',\n",
       " '_redhalf',\n",
       " '_redlines',\n",
       " '_redshoulders',\n",
       " '_redshoulderspattern_ra',\n",
       " '_redstripes',\n",
       " '_scga',\n",
       " '_shouldersonwhite',\n",
       " '_som',\n",
       " '_sq_mi',\n",
       " '_station',\n",
       " '_stripes_blue',\n",
       " '_stripes_red',\n",
       " '_stripes_white',\n",
       " '_stripesonblack',\n",
       " '_stripesonwhite',\n",
       " '_summer_olympics',\n",
       " '_telectromotive',\n",
       " '_tenge_front_small',\n",
       " '_thinblacksides',\n",
       " '_thinbluesides',\n",
       " '_thingreensides',\n",
       " '_thinorangesides',\n",
       " '_thinorangesidespattern_ra',\n",
       " '_thinsidesonwhite',\n",
       " '_thinstripesonwhite',\n",
       " '_thinwhitesides',\n",
       " '_title',\n",
       " '_tour_de_france',\n",
       " '_training',\n",
       " '_triple_sensor_watch',\n",
       " '_turgesius_island',\n",
       " '_type',\n",
       " '_ukra',\n",
       " '_venezia',\n",
       " '_visee',\n",
       " '_vneckwhite',\n",
       " '_vorderasiatisches_museum_',\n",
       " '_wga',\n",
       " '_white_hoops',\n",
       " '_whiteborder',\n",
       " '_whitecross',\n",
       " '_whitehoops',\n",
       " '_whitehorizontal',\n",
       " '_whitehorizontalcurl',\n",
       " '_whitelines',\n",
       " '_whitelower',\n",
       " '_whiteshoulders',\n",
       " '_whitesmalllower',\n",
       " '_whitestripeonright',\n",
       " '_whitestripes',\n",
       " '_width',\n",
       " '_wing',\n",
       " '_women',\n",
       " '_x',\n",
       " '_xin',\n",
       " '_y',\n",
       " '_yellowhorizontal',\n",
       " '_yellowshoulders',\n",
       " '_zhong',\n",
       " 'a_',\n",
       " 'a____________________',\n",
       " 'a____________________lower',\n",
       " 'a______a________',\n",
       " 'a_____b___',\n",
       " 'a_a_',\n",
       " 'a_a_a_',\n",
       " 'a_block',\n",
       " 'a_blockendinvoke',\n",
       " 'a_c_',\n",
       " 'a_i',\n",
       " 'a_j',\n",
       " 'a_k',\n",
       " 'a_m',\n",
       " 'a_message',\n",
       " 'a_n',\n",
       " 'a_nz',\n",
       " 'aa',\n",
       " 'aaa',\n",
       " 'aaaa',\n",
       " 'aaaaaaame',\n",
       " 'aaaah',\n",
       " 'aaaas',\n",
       " 'aaaawwsffaqf',\n",
       " 'aaai',\n",
       " 'aaanh',\n",
       " 'aaartiste',\n",
       " 'aaawwtwttttnnnaaannn',\n",
       " 'aaayubbed',\n",
       " 'aab',\n",
       " 'aab_football',\n",
       " 'aaba',\n",
       " 'aabb',\n",
       " 'aabba',\n",
       " 'aabhelli',\n",
       " 'aabrjnaabhuumi',\n",
       " 'aabuuaichyaaf',\n",
       " 'aac',\n",
       " 'aachen',\n",
       " 'aachencarpetswe',\n",
       " 'aachenuniversity',\n",
       " 'aachiiph',\n",
       " 'aachuur',\n",
       " 'aacs',\n",
       " 'aad',\n",
       " 'aaddaalupe',\n",
       " 'aaddiddaas',\n",
       " 'aaddlph',\n",
       " 'aaddns',\n",
       " 'aaddolph',\n",
       " 'aaddress',\n",
       " 'aadi',\n",
       " 'aadidaas',\n",
       " 'aadiikr',\n",
       " 'aadylup',\n",
       " 'aae',\n",
       " 'aaec',\n",
       " 'aaephchii',\n",
       " 'aafrika',\n",
       " 'aages',\n",
       " 'aagr',\n",
       " 'aagraa',\n",
       " 'aagriculture',\n",
       " 'aagrtlaa',\n",
       " 'aagstts',\n",
       " 'aah',\n",
       " 'aahaatti',\n",
       " 'aahaattii',\n",
       " 'aahs',\n",
       " 'aai',\n",
       " 'aaibiem',\n",
       " 'aailddaar',\n",
       " 'aainttraakhtt',\n",
       " 'aairn',\n",
       " 'aais',\n",
       " 'aaja',\n",
       " 'aajaaki',\n",
       " 'aajilyaandd',\n",
       " 'aajnylu',\n",
       " 'aakaasyaannaanaachaatifiinikchskaayhaareb',\n",
       " 'aakaasyaannaanaachaatikawlaalamep',\n",
       " 'aakaasyaannaanaachaatiw',\n",
       " 'aakbi',\n",
       " 'aakhaar',\n",
       " 'aakitekcharu',\n",
       " 'aakkoset',\n",
       " 'aakp',\n",
       " 'aakrrrrinaiddukll',\n",
       " 'aaksum',\n",
       " 'aal',\n",
       " 'aalaabaamaa',\n",
       " 'aalaamaa',\n",
       " 'aalber',\n",
       " 'aalbergbest',\n",
       " 'aalborg',\n",
       " 'aalekjaanddaar',\n",
       " 'aalen',\n",
       " 'aalenian',\n",
       " 'aali',\n",
       " 'aalii',\n",
       " 'aaliyah',\n",
       " 'aaljeriy',\n",
       " 'aalleh',\n",
       " 'aalok',\n",
       " 'aalor',\n",
       " 'aalphaa',\n",
       " 'aalphonso',\n",
       " 'aalscholver',\n",
       " 'aalsmeer',\n",
       " 'aalst',\n",
       " 'aalstcriterium',\n",
       " 'aalto',\n",
       " 'aalttaanttik',\n",
       " 'aalttaar',\n",
       " 'aalyaan',\n",
       " 'aam',\n",
       " 'aamai',\n",
       " 'aame',\n",
       " 'aamerig',\n",
       " 'aamerigo',\n",
       " 'aami',\n",
       " 'aamir',\n",
       " 'aamirun',\n",
       " 'aamsttrttm',\n",
       " 'aan',\n",
       " 'aanaa',\n",
       " 'aanaacchakr',\n",
       " 'aanaacchakrthangsaamkh',\n",
       " 'aanaacchakrthuuchichiliis',\n",
       " 'aanaars',\n",
       " 'aanchieta',\n",
       " 'aanddersen',\n",
       " 'aanddr',\n",
       " 'aanddroomiidd',\n",
       " 'aanddrs',\n",
       " 'aandoln',\n",
       " 'aandsliv',\n",
       " 'aandslivthe',\n",
       " 'aangkilk',\n",
       " 'aanihuulet',\n",
       " 'aaniy',\n",
       " 'aannaabaa',\n",
       " 'aannau',\n",
       " 'aanni',\n",
       " 'aannttu',\n",
       " 'aannvrriyaakrrrrr',\n",
       " 'aano',\n",
       " 'aanokiy',\n",
       " 'aanphraanko',\n",
       " 'aanphrgibhen',\n",
       " 'aanrr',\n",
       " 'aanrrigv',\n",
       " 'aanrrnn',\n",
       " 'aansrrrrrddaan',\n",
       " 'aanstoos',\n",
       " 'aantonioni',\n",
       " 'aantrjaatik',\n",
       " 'aanttiguv',\n",
       " 'aany',\n",
       " 'aanzet',\n",
       " 'aao',\n",
       " 'aap',\n",
       " 'aapbl',\n",
       " 'aaph',\n",
       " 'aaphgaanistaaner',\n",
       " 'aaphgaanistaanr',\n",
       " 'aaphrikaa',\n",
       " 'aapirikk',\n",
       " 'aapke',\n",
       " 'aapl',\n",
       " 'aapneanjali',\n",
       " 'aapolloniy',\n",
       " 'aappalaartoq',\n",
       " 'aappill',\n",
       " 'aapril',\n",
       " 'aapt',\n",
       " 'aapth',\n",
       " 'aar',\n",
       " 'aaraak',\n",
       " 'aaraaraat',\n",
       " 'aaraat',\n",
       " 'aarau',\n",
       " 'aarburg',\n",
       " 'aarch',\n",
       " 'aard',\n",
       " 'aardappeleters',\n",
       " 'aardappeloproer',\n",
       " 'aardd',\n",
       " 'aarden',\n",
       " 'aardman',\n",
       " 'aardo',\n",
       " 'aardshock',\n",
       " 'aardvark',\n",
       " 'aardvarks',\n",
       " 'aare',\n",
       " 'aarekhiiy',\n",
       " 'aaremeniiy',\n",
       " 'aareth',\n",
       " 'aargau',\n",
       " 'aargaucategory',\n",
       " 'aarhus',\n",
       " 'aarhusden',\n",
       " 'aari',\n",
       " 'aaria',\n",
       " 'aariinaa',\n",
       " 'aarkeyaa',\n",
       " 'aarkiyaa',\n",
       " 'aarkkutt',\n",
       " 'aarl',\n",
       " 'aarmeniiy',\n",
       " 'aarmeniyn',\n",
       " 'aarmi',\n",
       " 'aarmuhle',\n",
       " 'aarn',\n",
       " 'aarnestt',\n",
       " 'aarnstt',\n",
       " 'aaron',\n",
       " 'aaronic',\n",
       " 'aaronsohn',\n",
       " 'aaroooa',\n",
       " 'aarschot',\n",
       " 'aarsens',\n",
       " 'aarseth',\n",
       " 'aarstad',\n",
       " 'aarthaar',\n",
       " 'aarthik',\n",
       " 'aarthr',\n",
       " 'aartr',\n",
       " 'aarts',\n",
       " 'aarzoopooja',\n",
       " 'aas',\n",
       " 'aasa',\n",
       " 'aasasin',\n",
       " 'aasee',\n",
       " 'aaseestadt',\n",
       " 'aashinttn',\n",
       " 'aashiqsonia',\n",
       " 'aashura',\n",
       " 'aashuurr',\n",
       " 'aasia',\n",
       " 'aasian',\n",
       " 'aasif',\n",
       " 'aasifaq',\n",
       " 'aasii',\n",
       " 'aasivaq',\n",
       " 'aasle',\n",
       " 'aasmund',\n",
       " 'aasptte',\n",
       " 'aastireeliyaa',\n",
       " 'aasttreliyaa',\n",
       " 'aat',\n",
       " 'aataustralian',\n",
       " 'aatmaa',\n",
       " 'aatomkell',\n",
       " 'aatrium',\n",
       " 'aatthvaa',\n",
       " 'aau',\n",
       " 'aaugust',\n",
       " 'aaugustus',\n",
       " 'aauivy',\n",
       " 'aav',\n",
       " 'aava',\n",
       " 'aave',\n",
       " 'aavelin',\n",
       " 'aavik',\n",
       " 'aavikisms',\n",
       " 'aavikkokettu',\n",
       " 'aavnn',\n",
       " 'aavrt',\n",
       " 'aavrtti',\n",
       " 'aavrttnnn',\n",
       " 'aavrttnppttttik',\n",
       " 'aavso',\n",
       " 'aavsth',\n",
       " 'aaw',\n",
       " 'aawhaangocchw',\n",
       " 'aax',\n",
       " 'aay',\n",
       " 'aayaan',\n",
       " 'aayaurved',\n",
       " 'aayegi',\n",
       " 'aayngsttraam',\n",
       " 'aayog',\n",
       " 'aayurved',\n",
       " 'aayurveed',\n",
       " 'aayurveedn',\n",
       " 'ab',\n",
       " 'aba',\n",
       " 'abaama',\n",
       " 'abab',\n",
       " 'ababa',\n",
       " 'ababaitalian',\n",
       " 'ababca',\n",
       " 'abaca',\n",
       " 'abacab',\n",
       " 'abacaxi',\n",
       " 'abacha',\n",
       " 'abaci',\n",
       " 'aback',\n",
       " 'abaco',\n",
       " 'abacus',\n",
       " 'abad',\n",
       " 'abadan',\n",
       " 'abadia',\n",
       " 'abadie',\n",
       " 'abadszalok',\n",
       " 'abafana',\n",
       " 'abag',\n",
       " 'abagaro',\n",
       " 'abagatan',\n",
       " 'abahlala',\n",
       " 'abahluphekela',\n",
       " 'abaiang',\n",
       " 'abaiangtarawabairiki',\n",
       " 'abaixo',\n",
       " 'abajo',\n",
       " 'abajoensis',\n",
       " 'abaju',\n",
       " 'abaka',\n",
       " 'abakan',\n",
       " 'abalanzose',\n",
       " 'aballo',\n",
       " 'aballum',\n",
       " 'abalone',\n",
       " 'abalus',\n",
       " 'abama',\n",
       " 'abamia',\n",
       " 'aban',\n",
       " 'abanaagliaracazdavaybozkurtcatalzeytincidedadaydevrekanidoganyurthanonuihsangaziinebolukastamonukurepinarbasisenpazarseydilertaskoprutosyahistoryit',\n",
       " 'abancay',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abandonedcommunities',\n",
       " 'abandonedhonoursdomestic',\n",
       " 'abandoning',\n",
       " 'abandonment',\n",
       " 'abandons',\n",
       " 'abandonware',\n",
       " 'abangane',\n",
       " 'abantiades',\n",
       " 'abantu',\n",
       " 'abap',\n",
       " 'abaqa',\n",
       " 'abarai',\n",
       " 'abarama',\n",
       " 'abaranger',\n",
       " 'abarangerpower',\n",
       " 'abarangers',\n",
       " 'abarca',\n",
       " 'abarcabase',\n",
       " 'abaribe',\n",
       " 'abaris',\n",
       " 'abarot',\n",
       " 'abarquero',\n",
       " 'abarth',\n",
       " 'abas',\n",
       " 'abasas',\n",
       " 'abascal',\n",
       " 'abasebenzela',\n",
       " 'abasement',\n",
       " 'abasgian',\n",
       " 'abasgoi',\n",
       " 'abass',\n",
       " 'abast',\n",
       " 'abasteciose',\n",
       " 'abastos',\n",
       " 'abastoslos',\n",
       " 'abatan',\n",
       " 'abate',\n",
       " 'abated',\n",
       " 'abatellis',\n",
       " 'abatement',\n",
       " 'abatidisimo',\n",
       " 'abating',\n",
       " 'abattoir',\n",
       " 'abattu',\n",
       " 'abauj',\n",
       " 'abaumuahiaigberealayiarochukwuabiribaitemisialangwaohafiankporoomobaikwuanoisuikwuatoakweteobehiemgbokobendeosisioma',\n",
       " 'abaxial',\n",
       " 'abaxo',\n",
       " 'abayarde',\n",
       " 'abaz',\n",
       " 'abazcaro',\n",
       " 'abazins',\n",
       " 'abazovlonely',\n",
       " 'abb',\n",
       " 'abba',\n",
       " 'abbaandersson',\n",
       " 'abbaas',\n",
       " 'abbacadabra',\n",
       " 'abbacy',\n",
       " 'abbada',\n",
       " 'abbado',\n",
       " 'abbaholics',\n",
       " 'abbans',\n",
       " 'abbas',\n",
       " 'abbasi',\n",
       " 'abbasid',\n",
       " 'abbasids',\n",
       " 'abbaskish',\n",
       " 'abbass',\n",
       " 'abbassid',\n",
       " 'abbate',\n",
       " 'abbatia',\n",
       " 'abbatial',\n",
       " 'abbaye',\n",
       " 'abbba',\n",
       " 'abbe',\n",
       " 'abbekinomichibudo',\n",
       " 'abbenes',\n",
       " 'abberline',\n",
       " 'abberrant',\n",
       " 'abbes',\n",
       " 'abbess',\n",
       " 'abbeville',\n",
       " 'abbey',\n",
       " 'abbeyboultham',\n",
       " 'abbeycategory',\n",
       " 'abbeydambusters',\n",
       " 'abbeyfeale',\n",
       " 'abbeygerard',\n",
       " 'abbeyholy',\n",
       " 'abbeyit',\n",
       " 'abbeypublic',\n",
       " 'abbeys',\n",
       " 'abbeywaltham',\n",
       " 'abbiamo',\n",
       " 'abbie',\n",
       " 'abbildung',\n",
       " 'abbondanzieri',\n",
       " 'abborfisker',\n",
       " 'abborrlika',\n",
       " 'abbot',\n",
       " 'abbots',\n",
       " 'abbotskonrad',\n",
       " 'abbott',\n",
       " 'abbottstanislaw',\n",
       " 'abbr',\n",
       " 'abbrev',\n",
       " 'abbrevation',\n",
       " 'abbreviate',\n",
       " 'abbreviated',\n",
       " 'abbreviating',\n",
       " 'abbreviation',\n",
       " 'abbreviationdouble',\n",
       " 'abbreviationlist',\n",
       " 'abbreviations',\n",
       " 'abbreviationsneologismpseudo',\n",
       " 'abbreviationson',\n",
       " 'abbreviationsudan',\n",
       " 'abbreviator',\n",
       " 'abbs',\n",
       " 'abbt',\n",
       " 'abbud',\n",
       " 'abbuffata',\n",
       " 'abby',\n",
       " 'abbyanimals',\n",
       " 'abbythe',\n",
       " 'abbyy',\n",
       " 'abc',\n",
       " 'abca',\n",
       " 'abcabc',\n",
       " 'abcb',\n",
       " 'abcbc',\n",
       " 'abcbce',\n",
       " 'abcbf',\n",
       " 'abcd',\n",
       " 'abcde',\n",
       " 'abcdef',\n",
       " 'abcdefghijklmnopqrstuvwxyzin',\n",
       " 'abcdefghijklmnopqrstuvwxyzminuscule',\n",
       " 'abce',\n",
       " 'abchasen',\n",
       " 'abchazai',\n",
       " 'abchazci',\n",
       " 'abchazen',\n",
       " 'abchazer',\n",
       " 'abchazove',\n",
       " 'abchazowie',\n",
       " 'abciximab',\n",
       " 'abclist',\n",
       " 'abcn',\n",
       " 'abcnews',\n",
       " 'abcoude',\n",
       " 'abcs',\n",
       " 'abctoon',\n",
       " 'abd',\n",
       " 'abda',\n",
       " 'abdabs',\n",
       " 'abdala',\n",
       " 'abdalazis',\n",
       " 'abdallah',\n",
       " 'abdallahi',\n",
       " 'abdallahjassem',\n",
       " 'abdel',\n",
       " 'abdelazar',\n",
       " 'abdelaziz',\n",
       " 'abdelghani',\n",
       " 'abdelkader',\n",
       " 'abdellah',\n",
       " 'abdelouahed',\n",
       " 'abdelwahab',\n",
       " 'abdera',\n",
       " 'abderadidymoteicho',\n",
       " 'abderraman',\n",
       " 'abdicate',\n",
       " 'abdicated',\n",
       " 'abdicates',\n",
       " 'abdicating',\n",
       " 'abdication',\n",
       " 'abdicationelection',\n",
       " 'abdicationlist',\n",
       " 'abdicsarajevo',\n",
       " 'abdin',\n",
       " 'abdo',\n",
       " 'abdolvahab',\n",
       " 'abdomen',\n",
       " 'abdomenal',\n",
       " 'abdomenliver',\n",
       " 'abdomens',\n",
       " 'abdominal',\n",
       " 'abdominis',\n",
       " 'abdomino',\n",
       " 'abdominopelvic',\n",
       " 'abdominoperineal',\n",
       " 'abdou',\n",
       " 'abdoujaparov',\n",
       " 'abdoulatifou',\n",
       " 'abdoulaye',\n",
       " 'abdu',\n",
       " 'abdual',\n",
       " 'abducens',\n",
       " 'abducent',\n",
       " 'abduct',\n",
       " 'abducted',\n",
       " 'abducting',\n",
       " 'abduction',\n",
       " 'abductions',\n",
       " 'abductor',\n",
       " 'abductors',\n",
       " 'abdul',\n",
       " 'abdulaziz',\n",
       " 'abdulazizs',\n",
       " 'abdulkarim',\n",
       " 'abdulkhadzhiev',\n",
       " 'abdullaev',\n",
       " 'abdullah',\n",
       " 'abdulmecid',\n",
       " 'abdulov',\n",
       " 'abdulrahman',\n",
       " 'abdulsalami',\n",
       " 'abdur',\n",
       " 'abdurahman',\n",
       " 'abdurajak',\n",
       " 'abdurajik',\n",
       " 'abdurashid',\n",
       " 'abdurrashid',\n",
       " 'abdylazyz',\n",
       " 'abdylonymus',\n",
       " 'abe',\n",
       " 'abeabano',\n",
       " 'abebe',\n",
       " 'abecadlo',\n",
       " 'abecasios',\n",
       " 'abece',\n",
       " 'abecedaire',\n",
       " 'abecedarium',\n",
       " 'abecele',\n",
       " 'abecs',\n",
       " 'abed',\n",
       " 'abeel',\n",
       " 'abegeben',\n",
       " 'abegglencharles',\n",
       " 'abeill',\n",
       " 'abejorreo',\n",
       " 'abel',\n",
       " 'abela',\n",
       " 'abelard',\n",
       " 'abelardo',\n",
       " 'abeleira',\n",
       " 'abelevskaia',\n",
       " 'abelha',\n",
       " 'abelhalulu',\n",
       " 'abelhamilton',\n",
       " 'abelian',\n",
       " 'abelis',\n",
       " 'abelisaurus',\n",
       " 'abellanera',\n",
       " 'abelova',\n",
       " 'abelpreis',\n",
       " 'abelprijs',\n",
       " 'abelprisen',\n",
       " 'abelpriset',\n",
       " 'abelsang',\n",
       " 'abelson',\n",
       " 'abelsverdlaunin',\n",
       " 'abelton',\n",
       " 'abeltzaintza',\n",
       " 'abelungu',\n",
       " 'abemama',\n",
       " 'abemamakuriatabontebike',\n",
       " 'aben',\n",
       " 'abencerraje',\n",
       " 'abencerrajes',\n",
       " 'abend',\n",
       " 'abendgluhn',\n",
       " 'abendroth',\n",
       " 'abendsegler',\n",
       " 'abengoa',\n",
       " 'abenteuer',\n",
       " 'abentofail',\n",
       " 'abenza',\n",
       " 'abeol',\n",
       " 'aber',\n",
       " 'aberace',\n",
       " 'aberacia',\n",
       " 'aberacija',\n",
       " 'aberatsiia',\n",
       " 'aberciusmalia',\n",
       " 'abercoc',\n",
       " 'abercrombie',\n",
       " 'aberdeen',\n",
       " 'aberdeenbbc',\n",
       " 'aberdeenroyal',\n",
       " 'aberdeenvictorian',\n",
       " 'aberdin',\n",
       " 'abere',\n",
       " 'abereiddy',\n",
       " 'aberenjenada',\n",
       " 'abergavenny',\n",
       " 'aberglaubens',\n",
       " 'aberiburandezi',\n",
       " 'aberman',\n",
       " 'abernathy',\n",
       " 'abernethy',\n",
       " 'aberplymm',\n",
       " 'aberra',\n",
       " 'aberraatio',\n",
       " 'aberracao',\n",
       " 'aberracion',\n",
       " 'aberracja',\n",
       " 'aberrant',\n",
       " 'aberratie',\n",
       " 'aberration',\n",
       " 'aberrational',\n",
       " 'aberrationas',\n",
       " 'aberrationbradley',\n",
       " 'aberrationdiurnal',\n",
       " 'aberrationnutationproper',\n",
       " 'aberrationplanetary',\n",
       " 'aberrations',\n",
       " 'aberrationthe',\n",
       " 'aberrationthere',\n",
       " 'aberratsiia',\n",
       " 'aberrazione',\n",
       " 'abertal',\n",
       " 'abertawe',\n",
       " 'abertay',\n",
       " 'aberto',\n",
       " 'abertondo',\n",
       " 'aberushang',\n",
       " 'aberutasuman',\n",
       " 'aberystwyth',\n",
       " 'abessalom',\n",
       " 'abessive',\n",
       " 'abesuthu',\n",
       " 'abetarda',\n",
       " 'abetka',\n",
       " 'abetted',\n",
       " 'abetting',\n",
       " 'abeville',\n",
       " 'abeyance',\n",
       " 'abeylegesse',\n",
       " 'abf',\n",
       " 'abfall',\n",
       " 'abfalle',\n",
       " 'abg',\n",
       " 'abgeordnetenhaus',\n",
       " 'abgineh',\n",
       " 'abh',\n",
       " 'abha',\n",
       " 'abhaasid',\n",
       " 'abhaasit',\n",
       " 'abhac',\n",
       " 'abhacphlainead',\n",
       " 'abhandlung',\n",
       " 'abhandlungen',\n",
       " 'abhaya',\n",
       " 'abhayaranya',\n",
       " 'abhazi',\n",
       " 'abhazlar',\n",
       " 'abhazoj',\n",
       " 'abhijit',\n",
       " 'abhishek',\n",
       " 'abhisit',\n",
       " 'abhor',\n",
       " 'abhorred',\n",
       " 'abhorrence',\n",
       " 'abhorrent',\n",
       " 'abhorring',\n",
       " 'abhors',\n",
       " 'abhoynagar',\n",
       " 'abhoypur',\n",
       " 'abhyaarnnyn',\n",
       " 'abhyvkaash',\n",
       " 'abi',\n",
       " 'abia',\n",
       " 'abiadura',\n",
       " 'abiastate',\n",
       " 'abiazhou',\n",
       " 'abib',\n",
       " 'abibe',\n",
       " 'abid',\n",
       " 'abidalother',\n",
       " 'abidcate',\n",
       " 'abide',\n",
       " 'abides',\n",
       " 'abidin',\n",
       " 'abiding',\n",
       " 'abidjan',\n",
       " 'abidla',\n",
       " 'abie',\n",
       " 'abiento',\n",
       " 'abierta',\n",
       " 'abiertainstituto',\n",
       " 'abierto',\n",
       " 'abiertu',\n",
       " 'abies',\n",
       " 'abietoideae',\n",
       " 'abif',\n",
       " 'abiff',\n",
       " 'abigail',\n",
       " 'abiirodo',\n",
       " 'abiit',\n",
       " 'abijah',\n",
       " 'abike',\n",
       " 'abilene',\n",
       " 'abilify',\n",
       " 'abilio',\n",
       " 'abilities',\n",
       " 'abilitiescategory',\n",
       " 'abilitiesin',\n",
       " 'ability',\n",
       " 'abillities',\n",
       " 'abimael',\n",
       " 'abingdon',\n",
       " 'abinterview',\n",
       " 'abiodun',\n",
       " 'abiogenesislist',\n",
       " 'abiogenic',\n",
       " 'abiotic',\n",
       " 'abipone',\n",
       " 'abipones',\n",
       " 'abiquy',\n",
       " 'abir',\n",
       " 'abis',\n",
       " 'abismado',\n",
       " 'abismo',\n",
       " 'abisola',\n",
       " 'abitazione',\n",
       " 'abiteboul',\n",
       " 'abitibi',\n",
       " 'abito',\n",
       " 'abitur',\n",
       " 'abiud',\n",
       " 'abiword',\n",
       " 'abjad',\n",
       " 'abjadi',\n",
       " 'abjar',\n",
       " 'abjasios',\n",
       " 'abject',\n",
       " 'abjection',\n",
       " 'abjuration',\n",
       " 'abjure',\n",
       " 'abjured',\n",
       " 'abkhaz',\n",
       " 'abkhazes',\n",
       " 'abkhazi',\n",
       " 'abkhazia',\n",
       " 'abkhaziaabkhazia',\n",
       " 'abkhaziaadjar',\n",
       " 'abkhaziaar',\n",
       " 'abkhazian',\n",
       " 'abkhazianotesexternal',\n",
       " 'abkhazians',\n",
       " 'abkhaziasukhumi',\n",
       " 'abkhaziathe',\n",
       " 'abkhazos',\n",
       " 'abkhazsem',\n",
       " 'abkhazy',\n",
       " 'abkhzym',\n",
       " 'abkommen',\n",
       " 'abl',\n",
       " 'abl_clio',\n",
       " 'ablaberdyeva',\n",
       " 'ablated',\n",
       " 'ablation',\n",
       " 'ablations',\n",
       " 'ablative',\n",
       " 'ablaut',\n",
       " 'ablautone',\n",
       " 'ablaze',\n",
       " 'able',\n",
       " 'ablest',\n",
       " 'ableton',\n",
       " 'ablh',\n",
       " 'ablon',\n",
       " 'abloy',\n",
       " 'abluere',\n",
       " 'ablukasi',\n",
       " 'ablum',\n",
       " 'ablution',\n",
       " 'ablutions',\n",
       " 'ably',\n",
       " 'abm',\n",
       " 'abma',\n",
       " 'abn',\n",
       " 'abna',\n",
       " 'abnadonne',\n",
       " 'abnakis',\n",
       " 'abnegation',\n",
       " 'abnegations',\n",
       " 'abner',\n",
       " 'abney',\n",
       " ...]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_tfidf_feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now we have to export data so we can work with it in the next sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_df = docs_df.drop(columns=[\"Name\", \"Text\", \"Lang\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "output = open('data/preproc_df.pkl', 'wb')\n",
    "pickle.dump (preproc_df, output)\n",
    "output.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
